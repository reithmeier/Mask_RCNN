# Depth Aware Mask RCNN

**Disclaimer:** This is a fork of
 [Mask R-CNN for Object Detection and Segmentation](https://github.com/matterport/Mask_RCNN)


## Requirements

* Python version 3.6
* required python libraries can be found [here](requirements.txt)
(CPU version) or [here](requirements_gpu.txt) (GPU version)
* (GPU only) [CUDA Toolkit 10.0](https://developer.nvidia.com/cuda-10.0-download-archive)
* (GPU only) [cudNN v7.6.3 (August 23, 2019), for CUDA 10.0](https://developer.nvidia.com/rdp/cudnn-archive)




## Datasets

This repository contains functionality to process the Sun RGB-D Dataset and the EDEN Elevator Dataset

### SUN RGB-D
1. Acquire the dataset: https://github.com/chrischoy/SUN_RGBD
1. Preprocess the dataset with [./samples/sun/preprocess.py](./samples/sun/preprocess.py)
1. open jupyter notebook with `jupyter notebook`
1. Inspect the dataset with [./samples/sun/inspect_data_d.ipynb](./samples/sun/inspect_data_d.ipynb), 
[./samples/sun/inspect_data_d3.ipynb](./samples/sun/inspect_data_d3.ipynb),
[./samples/sun/inspect_data_rgb.ipynb](./samples/sun/inspect_data_rgb.ipynb),
[./samples/sun/inspect_data_rgbd.ipynb](./samples/sun/inspect_data_rgbd.ipynb)
1. Train a model with [./samples/sun/train_model_d.ipynb](./samples/sun/train_model_d.ipynb), 
[./samples/sun/train_model_d3.ipynb](./samples/sun/train_model_d3.ipynb),
[./samples/sun/train_model_rgb.ipynb](./samples/sun/train_model_rgb.ipynb),
[./samples/sun/train_model_rgbd.ipynb](./samples/sun/train_model_rgbd.ipynb)

### EDEN Elevator
1. Aquire the dataset by processing ROS-Bag files with [./samples/elevator/realsense_reader.py](samples/elevator/data_generation/realsense_reader.py)
1. Label the dataset with https://github.com/heartexlabs/label-studio 
    1. `git clone https://github.com/heartexlabs/label-studio.git`
    1. change line 10 in docker-compose.yaml to `command: "label-studio start my_project --init --force --input-path=./my_project/path/to/rgb --input-format=image-dir --label-config='./my_project/path/to/new/config.xml'"`
    1. copy images generated by `realsense_reader.py` to `./my_project/path/to/rgb`
    1. copy `./samples/elevator/label-studio/config.xml` to `./my_project/path/to/new/config.xml`
    1. run it with docker-compose up -d
    1. label the data
    1. add the labels to the dataset with `python ./samples/elevator/rename_label_files.py -i label_studio_dir/my-project/completions/ -o dataset_dir`
1. split the data into train, validation, test with [./samples/elevator/split.py](samples/elevator/data_generation/split.py)
1. open jupyter notebook with `jupyter notebook`
1. Inspect the dataset with 
[./samples/elevator/inspect_data_d3.ipynb](./samples/elevator/inspect_data_d3.ipynb),
[./samples/elevator/inspect_data_rgb.ipynb](./samples/elevator/inspect_data_rgb.ipynb),
[./samples/elevator/inspect_data_rgbd.ipynb](./samples/elevator/inspect_data_rgbd.ipynb)
1. Train a model with 
[./samples/elevator/train_model_d3.ipynb](./samples/elevator/train_model_d3.ipynb),
[./samples/elevator/train_model_rgb.ipynb](./samples/elevator/train_model_rgb.ipynb),
[./samples/elevator/train_model_rgbd.ipynb](./samples/elevator/train_model_rgbd.ipynb)